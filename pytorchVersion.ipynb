{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e0fefc6-2701-4e53-a88b-8887593427b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from scipy.signal import butter, filtfilt, find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "51d2bdd9-b292-4e91-863d-1e020081b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Low Pass Filter for Azure data\n",
    "def butter_lowpass_filter(data, cutoff, order):\n",
    "    normal_cutoff=cutoff/(15) \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    x = np.expand_dims(filtfilt(b, a, data[:,0]), axis=-1)\n",
    "    y = np.expand_dims(filtfilt(b, a, data[:,1]), axis=-1)\n",
    "    z = np.expand_dims(filtfilt(b, a, data[:,2]), axis=-1)\n",
    "    filtered = np.concatenate((x, y, z), axis=-1)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5f21e669-14e0-43b1-9401-3d3df393c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadCSV(path):\n",
    "    \n",
    "    csv_data = np.loadtxt(path, delimiter=',', dtype=str, skiprows=1, usecols=(101))\n",
    "    idx_footSwitch = 0\n",
    "    for i in csv_data:\n",
    "        if i == ' 0':\n",
    "            idx_footSwitch += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    ## 누락된 데이터 전까지 읽기 위해 line_num 찾는 과정\n",
    "    csv_data = np.loadtxt(path, delimiter=',', dtype=str, skiprows=1, usecols=(1))\n",
    "    line_num=csv_data.shape[0]\n",
    "    for i, v in enumerate(csv_data):\n",
    "        if v == \" \":\n",
    "            line_num = i\n",
    "            break\n",
    "            \n",
    "    csv_data = np.loadtxt(path, delimiter=',', skiprows=1, max_rows=line_num, usecols=range(1, 101))  \n",
    "    \n",
    "    ## 마지막 4개의 항목을 통해 각 데이터가 기록된 시간을 획득(키넥트 기준)\n",
    "    time = csv_data[:,-4:]\n",
    "    time_ = time[:, 0] * 3600 + time[:,1] * 60 + time[:, 2]+ time[:, 3] / 1000.0\n",
    "    time_ = time_ - time_[0]\n",
    "    initialContactTime = time_[idx_footSwitch]\n",
    "    \n",
    "    ## 포즈 데이터 읽어오기\n",
    "    \n",
    "    # LPF를 위한 변수\n",
    "    cutoff = 6\n",
    "    order = 30\n",
    "    \n",
    "    pelvis_idx = 0\n",
    "    spine_naval_idx = 1\n",
    "    spine_chest_idx = 2\n",
    "    neck_idx = 3\n",
    "    \n",
    "    Pelvis = csv_data[:,pelvis_idx * 3:(pelvis_idx + 1) * 3]\n",
    "    Spine_naval = csv_data[:,spine_naval_idx * 3:(spine_naval_idx + 1) * 3]\n",
    "    Spine_chest = csv_data[:,spine_chest_idx * 3:(spine_chest_idx + 1) * 3]\n",
    "    Neck = csv_data[:,neck_idx * 3:(neck_idx + 1) * 3]\n",
    "    \n",
    "    Pelvis_filtered = butter_lowpass_filter(Pelvis, cutoff, order)\n",
    "    Spine_naval_filtered = butter_lowpass_filter(Spine_naval, cutoff, order)\n",
    "    Spine_chest_filtered = butter_lowpass_filter(Spine_chest, cutoff, order)\n",
    "    Neck_filtered = butter_lowpass_filter(Neck, cutoff, order)\n",
    "    \n",
    "    \n",
    "    LHip_idx = 18 \n",
    "    LKnee_idx = 19\n",
    "    LAnkle_idx = 20\n",
    "    RHip_idx = 22\n",
    "    RKnee_idx = 23\n",
    "    RAnkle_idx = 24\n",
    "    \n",
    "    LHip = csv_data[:, LHip_idx * 3: (LHip_idx + 1) * 3]\n",
    "    LKnee = csv_data[:, LKnee_idx * 3: (LKnee_idx + 1) * 3]\n",
    "    LAnkle = csv_data[:, LAnkle_idx * 3: (LAnkle_idx + 1) * 3]\n",
    "    \n",
    "    LHip_filtered = butter_lowpass_filter(LHip, cutoff, order)\n",
    "    LKnee_filtered = butter_lowpass_filter(LKnee, cutoff, order)\n",
    "    LAnkle_filtered = butter_lowpass_filter(LAnkle, cutoff, order)\n",
    "    \n",
    "    RHip = csv_data[:, RHip_idx * 3: (RHip_idx + 1) * 3]\n",
    "    RKnee = csv_data[:, RKnee_idx * 3: (RKnee_idx + 1) * 3]\n",
    "    RAnkle = csv_data[:, RAnkle_idx * 3: (RAnkle_idx + 1) * 3]\n",
    "    \n",
    "    RHip_filtered = butter_lowpass_filter(RHip, cutoff, order)\n",
    "    RKnee_filtered = butter_lowpass_filter(RKnee, cutoff, order)\n",
    "    RAnkle_filtered = butter_lowpass_filter(RAnkle, cutoff, order)\n",
    "\n",
    "    ## 발목거리\n",
    "    AngkleDistance = RAnkle_filtered - LAnkle_filtered\n",
    "    AngkleDistance = np.linalg.norm(AngkleDistance, axis=1, keepdims=True)\n",
    "    \n",
    "    ## 무릎각도\n",
    "    knee2hip = LHip_filtered - LKnee_filtered\n",
    "    knee2hip = knee2hip / np.linalg.norm(knee2hip, axis = 1, keepdims=True)\n",
    "    knee2angkle = LAnkle_filtered - LKnee_filtered\n",
    "    knee2angkle = knee2angkle / np.linalg.norm(knee2angkle, axis = 1, keepdims=True)\n",
    "    inner = np.sum(np.multiply(knee2hip, knee2angkle), axis=-1)\n",
    "    angle_Lknee = np.expand_dims(180 - np.arccos(inner) * 180 / np.pi, axis=-1)\n",
    "    \n",
    "    knee2hip = RHip_filtered - RKnee_filtered\n",
    "    knee2hip = knee2hip / np.linalg.norm(knee2hip, axis = 1, keepdims=True)\n",
    "    knee2angkle = RAnkle_filtered - RKnee_filtered\n",
    "    knee2angkle = knee2angkle / np.linalg.norm(knee2angkle, axis = 1, keepdims=True)\n",
    "    inner = np.sum(np.multiply(knee2hip, knee2angkle), axis=-1)\n",
    "    angle_Rknee = np.expand_dims(180 - np.arccos(inner) * 180 / np.pi, axis=-1)\n",
    "    \n",
    "    ## 엉덩이 각도\n",
    "    pelvis2naval = butter_lowpass_filter(Spine_naval, cutoff, order) - butter_lowpass_filter(Pelvis, cutoff, order)\n",
    "    pelvis2naval = pelvis2naval / np.linalg.norm(pelvis2naval, axis = 1, keepdims=True)\n",
    "    hip2knee = LKnee_filtered - LHip_filtered\n",
    "    hip2knee = hip2knee / np.linalg.norm(hip2knee, axis = 1, keepdims=True)\n",
    "    inner = np.sum(np.multiply(pelvis2naval, hip2knee), axis=-1)\n",
    "    angle_LHip = np.expand_dims(180 - np.arccos(inner) * 180 / np.pi, axis=-1)\n",
    "    \n",
    "    hip2knee = RKnee_filtered - RHip_filtered\n",
    "    hip2knee = hip2knee / np.linalg.norm(hip2knee, axis = 1, keepdims=True)\n",
    "    inner = np.sum(np.multiply(pelvis2naval, hip2knee), axis=-1)\n",
    "    angle_RHip = np.expand_dims(180 - np.arccos(inner) * 180 / np.pi, axis=-1)\n",
    "    \n",
    "    \n",
    "    ## pelvis to ankle\n",
    "    pevis2Lankle = Pelvis_filtered - LAnkle_filtered\n",
    "    pevis2Rankle = Pelvis_filtered - RAnkle_filtered\n",
    "    \n",
    "    # Safe Zone 설정\n",
    "    # Pelvis의 z방향 성분을 통해 어떤 프레임부터 어떤 프레임까지 사용할지 결정\n",
    "    # 카메라에서 먼 지점이 safe_start, 카메라에서 가까운 지점이 safe_end 이다.(피실험자는 카메라에서 먼 곳에서부터 카메라를 향해 보행함) \n",
    "    safe_start=0\n",
    "    safe_end=0\n",
    "    \n",
    "    # 현재 safe_start는 pelvis의 z방향 성분이 3300mm 이하로 떨어지는 지점, safe_end는 1350 이하로 떨어지는 지점\n",
    "    for i, v in enumerate(Pelvis[:, 2]):\n",
    "        if safe_start == 0 and v < 3300:\n",
    "            safe_start = i\n",
    "        if safe_start != 0 and v < 1350:\n",
    "            safe_end = i\n",
    "            break\n",
    "    \n",
    "    # data1은 왼다리, data2는 오른다리에 대한 Input(엉덩이각도, 무릎각도, 반대쪽 엉덩이각도, 반대쪽 무릎각도, 양 발목간의 거리)\n",
    "    # Output : 후처리 결과(true or false), data1, data2, initialContactTime(키넥트 시스템 기준), safe_start(프레임 넘버), safe_end(프레임 넘버)\n",
    "    data_l = np.concatenate((angle_LHip, angle_Lknee, angle_RHip, angle_Rknee, AngkleDistance), axis=-1)  \n",
    "    data_r = np.concatenate((angle_RHip, angle_Rknee, angle_LHip, angle_Lknee, AngkleDistance), axis=-1) \n",
    "    \n",
    "    return data_l, data_r, time_, initialContactTime, safe_start, safe_end, pevis2Lankle, pevis2Rankle\n",
    "    \n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c8612aa1-fcfa-4960-83ed-763bbe9f0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zebris에서 제공하는 pressure 데이터를 읽기 위한 함수\n",
    "# file은 각 trail 마다의 폴더경로\n",
    "def ReadForceData(path):\n",
    "    \n",
    "    # Parameters\n",
    "    path_parameters = os.path.join(path, \"parameters.csv\")\n",
    "    df = pd.read_csv(path_parameters)\n",
    "    df_extracted = df[['Step length L, cm', 'Stance phase L, %', 'Step length R, cm', 'Stance phase R, %', 'Stride length, cm', 'Cadence, steps/min', 'Velocity, km/h']]\n",
    "    #print(df_extracted.values.tolist()[0])\n",
    "    \n",
    "    # 각 폴더마다 양 발에 대한 bufferfly_force_curve 파일이 존재\n",
    "    path_l = os.path.join(path, \"butterfly_force_curve-L.csv\")\n",
    "    path_r = os.path.join(path, \"butterfly_force_curve-R.csv\")\n",
    "    \n",
    "    # 왼발에 대한 initial contact과 Toe off 지점을 찾는 파트\n",
    "    csv_data_l = np.loadtxt(path_l, delimiter=',', skiprows=4, usecols=range(2), encoding='utf-8')\n",
    "    Ltime = csv_data_l[:,0]\n",
    "    Lforce = csv_data_l[:,1]\n",
    "\n",
    "    l_contact = []\n",
    "    l_off = []\n",
    "    l_contact.append(Ltime[0])\n",
    "    pre = Ltime[0]\n",
    "    for i in Ltime:\n",
    "        if i - pre > 0.2:\n",
    "            l_contact.append(i)\n",
    "            if pre != 0:\n",
    "                l_off.append(pre + 0.01)\n",
    "        pre = i\n",
    "    l_off.append(Ltime[-1] + 0.01)\n",
    "    \n",
    "    # 오른발에 대한 initial contact과 Toe off 지점을 찾는 파트\n",
    "    csv_data_r = np.loadtxt(path_r, delimiter=',', skiprows=4, usecols=range(2), encoding='utf-8')\n",
    "    Rtime = csv_data_r[:,0]\n",
    "    Rforce = csv_data_r[:,1]\n",
    "\n",
    "    r_contact = []\n",
    "    r_off = []\n",
    "    r_contact.append(Rtime[0])\n",
    "    pre = Rtime[0]\n",
    "    for i in Rtime:\n",
    "        if i - pre > 0.2:\n",
    "            r_contact.append(i)\n",
    "            if pre != 0:\n",
    "                r_off.append(pre + 0.01)\n",
    "        pre = i\n",
    "    r_off.append(Rtime[-1] + 0.01)\n",
    "    \n",
    "    # Output : 후처리 결과(true or false), l_contact(시간 list), l_off(시간 list), r_contact(시간 list), r_off(시간 list)\n",
    "    return l_contact, l_off, r_contact, r_off, df_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "560374fd-e169-4a74-8b8e-04100bfde40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/LBL\n",
      "Dataset/PHE\n",
      "Dataset/LKO\n",
      "Dataset/UKO\n",
      "Dataset/SOS\n",
      "Dataset/KMK\n",
      "Dataset/LJE\n",
      "Dataset/HSN\n",
      "Dataset/KHM\n",
      "Dataset/LSJ\n",
      "Dataset/BYS\n",
      "Dataset/CSY\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38/4010396734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrawing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;31m#dataset = CustomDataset(root = 'Dataset_old', numFrame = 10, drawing = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38/4010396734.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, numFrame, drawing)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mdata_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialContactTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpevis2Lankle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpevis2Rankle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathCSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0ml_contact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_off\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_contact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_off\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadForceData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathForceData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38/4089393178.py\u001b[0m in \u001b[0;36mReadCSV\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcsv_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m## 마지막 4개의 항목을 통해 각 데이터가 기록된 시간을 획득(키넥트 기준)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, numFrame, drawing):\n",
    "        self.root = root\n",
    "        self.numFrame = numFrame\n",
    "        names = []\n",
    "        for name in next(os.walk(root))[1]:\n",
    "            names.append(name)\n",
    "        #print(names)\n",
    "        self.names = names\n",
    "        self.errorFiles = []\n",
    "        \n",
    "        #drawing을 위한 폴더 생성\n",
    "        if drawing:\n",
    "            if not os.path.isdir(\"./Inputs\"):\n",
    "                os.mkdir(\"Inputs\")\n",
    "            else:\n",
    "                shutil.rmtree(\"Inputs\")\n",
    "                os.mkdir(\"Inputs\")\n",
    "            \n",
    "        \n",
    "        # 인공지능을 학습하기 위한 모든 input과 output을 저장하기 위한 버퍼\n",
    "        inputs_buffer = np.zeros(shape=(1, numFrame, 5), dtype=np.float64)\n",
    "        outputs_buffer = np.zeros(shape=(1, ), dtype=np.float64)\n",
    "        \n",
    "        for name in self.names:\n",
    "            pathPerson = os.path.join(self.root, name)\n",
    "            print(pathPerson)\n",
    "            \n",
    "            (root, Folders, csvFiles) = next(os.walk(pathPerson))\n",
    "            Folders = sorted(Folders)\n",
    "            csvFiles = sorted(csvFiles)\n",
    "            \n",
    "            if '.ipynb_checkpoints' in Folders:\n",
    "                Folders.remove('.ipynb_checkpoints')\n",
    "            if '.ipynb_checkpoints' in csvFiles:\n",
    "                csvFiles.remove('.ipynb_checkpoints')\n",
    "            if len(Folders) != len(csvFiles):\n",
    "                print(name, ' is not matched')\n",
    "                break\n",
    "            \n",
    "            for idx_file in range(len(csvFiles)):\n",
    "                pathCSV = os.path.join(pathPerson, csvFiles[idx_file])\n",
    "                pathForceData = os.path.join(pathPerson, Folders[idx_file])\n",
    "                \n",
    "                #try:\n",
    "                data_l, data_r, time, initialContactTime, safe_start, safe_end, pevis2Lankle, pevis2Rankle = ReadCSV(pathCSV)\n",
    "                l_contact, l_off, r_contact, r_off, parameters = ReadForceData(pathForceData)\n",
    "\n",
    "                # 싱크 맞추기\n",
    "                firstContact = min(r_contact[0], l_contact[0]) # zebris 기준 최초 contact 찾음\n",
    "                timeGap = initialContactTime - firstContact # sync.kinect 기준으로 모든 시간 변환\n",
    "                l_contact = l_contact + timeGap\n",
    "                l_off = l_off + timeGap\n",
    "                r_contact = r_contact + timeGap\n",
    "                r_off = r_off + timeGap\n",
    "\n",
    "                # 정답 라벨\n",
    "                l_contact_ = []\n",
    "                for i in l_contact:\n",
    "                    tmp = abs(time - i)\n",
    "                    l_contact_.append(np.argmin(tmp))\n",
    "                l_off_ = []\n",
    "                for i in l_off:\n",
    "                    tmp = abs(time - i)\n",
    "                    l_off_.append(np.argmin(tmp))\n",
    "\n",
    "                l_label = np.zeros(data_l.shape[0])\n",
    "                for i in range(len(l_contact_)):\n",
    "                    for j in range(l_contact_[i], l_off_[i]):\n",
    "                        l_label[j] = 1\n",
    "\n",
    "                r_contact_ = []\n",
    "                for i in r_contact:\n",
    "                    tmp = abs(time - i)\n",
    "                    r_contact_.append(np.argmin(tmp))\n",
    "                r_off_ = []\n",
    "                for i in r_off:\n",
    "                    tmp = abs(time - i)\n",
    "                    r_off_.append(np.argmin(tmp))\n",
    "\n",
    "                r_label = np.zeros(data_r.shape[0])\n",
    "                for i in range(len(r_contact_)):\n",
    "                    for j in range(r_contact_[i], r_off_[i]):\n",
    "                        r_label[j] = 1\n",
    "\n",
    "                # 인공지능 인풋을 만들기 위한 루프\n",
    "                # safe_start와 safe_end 사이에서 numFrame(현재 10)개씩 잘라서 input 하나씩 생성\n",
    "                # input에 대한 결과는 l_label 또는 r_label을 이용해 파악\n",
    "                idx_startframe = safe_start\n",
    "                while (idx_startframe + numFrame-1) <= safe_end:\n",
    "                    ## L\n",
    "                    input_ = data_l[idx_startframe:idx_startframe+numFrame, :]\n",
    "                    min_ = np.min(input_,axis=0)\n",
    "                    max_ = np.max(input_,axis=0)\n",
    "                    input_ = (input_ - min_) / (max_ - min_)\n",
    "                    input_ = np.expand_dims(input_, axis=0)\n",
    "                    inputs_buffer = np.concatenate((inputs_buffer, input_), axis=0)\n",
    "\n",
    "                    output_ = l_label[idx_startframe+numFrame-1]\n",
    "                    outputs_buffer = np.concatenate((outputs_buffer, np.array([output_])), axis=0)\n",
    "                    #output_ = np.expand_dims(output_, axis=0)\n",
    "                    #outputs_buffer = np.concatenate((outputs_buffer, output_), axis=0)\n",
    "\n",
    "                    ## R\n",
    "                    input_ = data_r[idx_startframe:idx_startframe+numFrame, :]\n",
    "                    min_ = np.min(input_,axis=0)\n",
    "                    max_ = np.max(input_,axis=0)\n",
    "                    input_ = (input_ - min_) / (max_ - min_)\n",
    "                    input_ = np.expand_dims(input_, axis=0)\n",
    "                    inputs_buffer = np.concatenate((inputs_buffer, input_), axis=0)\n",
    "\n",
    "                    output_ = r_label[idx_startframe+numFrame-1]\n",
    "                    outputs_buffer = np.concatenate((outputs_buffer, np.array([output_])), axis=0)\n",
    "                    #output_ = np.expand_dims(output_, axis=0)\n",
    "                    #outputs_buffer = np.concatenate((outputs_buffer, output_), axis=0)\n",
    "                    idx_startframe += 1\n",
    "\n",
    "                # Drawing\n",
    "                if drawing:\n",
    "                    x_new = np.linspace(time[0], time[-1], len(time))\n",
    "                    fig, axs = plt.subplots(4, figsize=(18,12))\n",
    "\n",
    "                    ## Left Input\n",
    "                    axs[0].set_title('Left')\n",
    "                    axs[0].plot(x_new, data_l[:,0], 'r-', label = 'Hip')\n",
    "                    axs[0].plot(x_new, data_l[:,1], 'b-', label = 'Knee')\n",
    "                    axs[0].plot(x_new, data_l[:,4], 'k-', label = 'AnkleDistance')\n",
    "\n",
    "                    axs[0].axvline(x = time[l_contact_[0]], label='LContact', c='r')\n",
    "                    for i in l_contact_:\n",
    "                        axs[0].axvline(x = time[i], c='r')\n",
    "                    axs[0].axvline(x = time[l_off_[0]], label='LOff', c='b')\n",
    "                    for i in l_off_:\n",
    "                        axs[0].axvline(x = time[i], c='b')\n",
    "                    axs[0].axvline(x = time[safe_start], label='safe Start = {}'.format(safe_start), c='g')\n",
    "                    axs[0].axvline(x = time[safe_end], label='safe End = {}'.format(safe_end), c='g')\n",
    "                    axs[0].legend()\n",
    "\n",
    "                    ## Left Label\n",
    "                    axs[1].set_title('Left_label')\n",
    "\n",
    "                    for i, v in enumerate(l_label):\n",
    "                        if v == 1:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 0.7, 'b.', label='Swing')\n",
    "                                axs[1].plot(time[i], 0.7, 'r.', label='Stance')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 0.7, 'r.')\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 0.3, 'r.', label='Stance')\n",
    "                                axs[1].plot(time[i], 0.3, 'b.', label='Swing')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 0.3, 'b.')\n",
    "                    axs[1].axvline(x = time[safe_start], c='g')\n",
    "                    axs[1].axvline(x = time[safe_end], c='g')\n",
    "                    axs[1].legend()\n",
    "\n",
    "                    ## Right Input\n",
    "                    axs[2].set_title('Right')\n",
    "                    axs[2].plot(x_new, data_r[:,0], 'r-', label = 'Hip')\n",
    "                    axs[2].plot(x_new, data_r[:,1], 'b-', label = 'Knee')\n",
    "                    axs[2].plot(x_new, data_r[:,4], 'k-', label = 'AnkleDistance')\n",
    "                    axs[2].axvline(x = time[r_contact_[0]], label='RContact', c='r')\n",
    "                    for i in r_contact_:\n",
    "                        axs[2].axvline(x = time[i], c='r')\n",
    "                    axs[2].axvline(x = time[r_off_[0]], label='ROff', c='b')\n",
    "                    for i in r_off_:\n",
    "                        axs[2].axvline(x = time[i], c='b')\n",
    "                    axs[2].axvline(x = time[safe_start], label='safe Start = {}'.format(safe_start), c='g')\n",
    "                    axs[2].axvline(x = time[safe_end], label='safe End = {}'.format(safe_end), c='g')\n",
    "                    axs[2].legend()\n",
    "\n",
    "                    ## Right Label\n",
    "                    axs[3].set_title('Right_label')\n",
    "                    for i, v in enumerate(r_label):\n",
    "                        if v == 1:\n",
    "                            if i == 0:\n",
    "                                axs[3].plot(time[i], 0.7, 'b.', label='Swing')\n",
    "                                axs[3].plot(time[i], 0.7, 'r.', label='Stance')\n",
    "                            else:\n",
    "                                axs[3].plot(time[i], 0.7, 'r.')\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                axs[3].plot(time[i], 0.3, 'r.', label='Stance')\n",
    "                                axs[3].plot(time[i], 0.3, 'b.', label='Swing')\n",
    "                            else:\n",
    "                                axs[3].plot(time[i], 0.3, 'b.')\n",
    "                    axs[3].axvline(x = time[safe_start], c='g')\n",
    "                    axs[3].axvline(x = time[safe_end], c='g')\n",
    "                    axs[3].legend()\n",
    "\n",
    "\n",
    "                    for ax in axs:\n",
    "                        ax.set_xlim([x_new[0], x_new[-1]])\n",
    "\n",
    "                    fig.tight_layout()\n",
    "                    plt.savefig('Inputs//' + csvFiles[idx_file].split('.')[0] + '.jpg')\n",
    "                    plt.close()\n",
    "\n",
    "                    \n",
    "                #except:\n",
    "                #    self.errorFiles.append(csvFiles[idx_file].split('.')[0])\n",
    "                \n",
    "                #AzureData(pathCSV)\n",
    "        inputs_buffer = np.delete(inputs_buffer, [0,0,0,0,0], axis=0)\n",
    "        outputs_buffer = np.delete(outputs_buffer, [0], axis=0)\n",
    "        #print(inputs_buffer.shape)\n",
    "        #self.x_data = np.swapaxes(inputs_buffer, 1, 2)\n",
    "        self.x_data = inputs_buffer\n",
    "        #print(self.x_data.shape)\n",
    "        self.y_data = outputs_buffer\n",
    "        print(self.y_data.shape)\n",
    "        print(\"Finish !\")\n",
    "        if len(self.errorFiles) > 0:\n",
    "            print(self.errorFiles)\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx,:,:])\n",
    "        y = torch.FloatTensor([self.y_data[idx]])\n",
    "        return x, y\n",
    "    \n",
    "dataset = CustomDataset(root = 'Dataset', numFrame = 10, drawing = False)\n",
    "#dataset = CustomDataset(root = 'Dataset_old', numFrame = 10, drawing = True)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_dataset, test_dataset = random_split(dataset,[train_size, test_size])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cd50e-0a26-4251-9bfb-6239e3f37efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 CPU나 GPU 장치를 얻습니다.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(\"Using {} device\".format(device))\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "class tcnPhase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(tcnPhase, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=5, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(3, 3, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(3, 3, 3, stride=1, padding=1)\n",
    "        \n",
    "        self.input_size = 3\n",
    "        self.hidden_size = 3\n",
    "        self.num_layers = 1 \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.fc = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x, h0, c0):\n",
    "        #x = torch.swapaxes(x, 1, 2)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = torch.swapaxes(x, 1, 2)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = out[:,-1,:]\n",
    "        \n",
    "        x = self.fc(out)\n",
    "        x = torch.sigmoid(x)\n",
    "        #return out, (hn, cn)\n",
    "        return x\n",
    "model = tcnPhase().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1bdb55f4-ba62-4e6a-83cf-96776c90161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "hidden_size = 3\n",
    "proj_size = 1\n",
    "num_layers = 1\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train(True)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        model.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        h0 = torch.zeros(1, X.size(0), hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, X.size(0), hidden_size).to(device)\n",
    "        pred = model(X, h0.detach(), c0.detach())\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \"\"\"\n",
    "        if batch % 400 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \"\"\"\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            h0 = torch.zeros(1, X.size(0), hidden_size).to(device)\n",
    "            c0 = torch.zeros(1, X.size(0), hidden_size).to(device)\n",
    "            pred = model(X, h0.detach(), c0.detach())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    #correct /= size\n",
    "    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c33bb73-67fd-47fa-8112-7a8232dbcac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1819\n",
      "-------------------------------\n",
      "Avg loss: 0.460679 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "patience = 50\n",
    "stopped_epoch = 0\n",
    "best = np.Inf\n",
    "wait = 0\n",
    "PATH = 'Mymodel'\n",
    "    \n",
    "for t in range(EPOCHS):\n",
    "    clear_output(wait=True)\n",
    "    #if t%50 == 0:\n",
    "    #    clear_output(wait=True)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    testLoss = test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    if testLoss < best:\n",
    "        best = testLoss\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            stopped_epoch = t\n",
    "            device = torch.device(\"cuda\")\n",
    "            model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "            model.to(device)\n",
    "            break\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04fa7d18-6ad1-45fa-be7f-fa8fff3503d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tcnPhase(\n",
       "  (conv1): Conv1d(5, 3, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(3, 3, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv3): Conv1d(3, 3, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (lstm): LSTM(3, 3, batch_first=True)\n",
       "  (fc): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'Mymodel'\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "92c31a3b-e1b8-4e0c-962c-16ffa1532437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruleBased(numFrame, safe_start, safe_end, pevis2Lankle, pevis2Rankle, PostProcessing_):\n",
    "    # Safe Zone안에 데이터만 다룸\n",
    "    pevis2Lankle = pevis2Lankle[safe_start + numFrame - 1:safe_end + 1, -1]\n",
    "    pevis2Rankle = pevis2Rankle[safe_start + numFrame - 1:safe_end + 1, -1]\n",
    "    \n",
    "    # For Left\n",
    "    LContact, _ = find_peaks(pevis2Lankle,  distance=3)\n",
    "    LOff, _ = find_peaks(-pevis2Lankle,  distance=3)\n",
    "    \n",
    "    tmp = 0\n",
    "    if LContact[0] > LOff[0]:\n",
    "        tmp = 1\n",
    "    l_answer = []\n",
    "    for i in range(pevis2Lankle.shape[0]):\n",
    "        if i in LContact:\n",
    "            tmp = 1\n",
    "        elif i in LOff:\n",
    "            tmp = 0\n",
    "        l_answer.append(tmp)\n",
    "        \n",
    "    # For Right\n",
    "    RContact, _ = find_peaks(pevis2Rankle, distance=3)\n",
    "    ROff, _ = find_peaks(-pevis2Rankle, distance=3)\n",
    "    \n",
    "    tmp = 0\n",
    "    if RContact[0] > ROff[0]:\n",
    "        tmp = 1\n",
    "    r_answer = []\n",
    "    for i in range(pevis2Rankle.shape[0]):\n",
    "        if i in RContact:\n",
    "            tmp = 1\n",
    "        elif i in ROff:\n",
    "            tmp = 0\n",
    "        r_answer.append(tmp)\n",
    "        \n",
    "    finalAnswer_l = None\n",
    "    finalAnswer_r = None\n",
    "    \n",
    "    if PostProcessing_:\n",
    "        finalAnswer_l = PostProcessing(answer = l_answer, threshold = 3)\n",
    "        finalAnswer_r = PostProcessing(answer = r_answer, threshold = 3)\n",
    "    else:\n",
    "        finalAnswer_l = l_answer\n",
    "        finalAnswer_r = r_answer\n",
    "        \n",
    "        \n",
    "    return finalAnswer_l, finalAnswer_r, l_answer, r_answer\n",
    "            \n",
    "#finalAnswer_l, finalAnswer_r = ruleBased(numFrame = 10, path = './Dataset/BYS/BYS_00.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "30fdab07-0925-43fd-9e5c-c512a016bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PostProcessing(answer, threshold):\n",
    "    # L\n",
    "    # count : 연속적인 gait Phase를 세기 위한 변수\n",
    "    # prev : 바로 직전의 gait phase\n",
    "    # mark_unstable : 불연속적인 구간기록\n",
    "    count = 0\n",
    "    prev = answer[0]\n",
    "    mark_unstable = []\n",
    "    for i, answer_ in enumerate(answer):\n",
    "        # Gait Phase가 바뀌는 시점\n",
    "        if prev != answer_:\n",
    "            # count가 정해준 threshold를 넘어갔을 때, 즉 연속적인 구간일 때 0\n",
    "            if count > threshold:\n",
    "                mark_unstable += [0] * count\n",
    "            # count가 정해준 threshold보다 작을 때, 즉 불연속적인 구간일 때 -1\n",
    "            else:\n",
    "                mark_unstable += [-1] * count\n",
    "            count = 1\n",
    "        # Gait Phase가 바뀌지 않는 시점\n",
    "        # count 만 올라감\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "        # Gait answer 끝부분에 대한 처리구간\n",
    "        if i == len(answer) - 1:\n",
    "            # 끝부분에 다다랐을 때 count가 threshold를 넘어갔을 때, 즉 연속적인 구간일 때 0\n",
    "            if count > threshold:\n",
    "                mark_unstable += [0] * count\n",
    "            # 끝부분에 다다랐을 때 count가 threshold보다 작을 때, 즉 불연속적인 구간일 때 -1\n",
    "            else:\n",
    "                mark_unstable += [-1] * count\n",
    "\n",
    "        prev = answer_\n",
    "    #print(mark_unstable)\n",
    "\n",
    "    \n",
    "    # 위에서 기록한 mark_unstable를 근거로 range_unstable 생성\n",
    "    # 생성된 range_unstable은 불연속적인 구간들의 처음과 끝을 묶은 리스트들로 구성\n",
    "    # 예) [[1, 3], [8, 13], ...]\n",
    "    unstable = False\n",
    "    range_unstable = []\n",
    "    tmp = []\n",
    "    for i, v in enumerate(mark_unstable):\n",
    "        # tmp가 하나의 불연속적인 구간을 나타냄\n",
    "        if v == -1 and not unstable:\n",
    "            tmp.append(i)\n",
    "            unstable = True\n",
    "        elif v != -1 and unstable:\n",
    "            tmp.append(i)\n",
    "            range_unstable.append(tmp)\n",
    "            tmp = []\n",
    "            unstable = False\n",
    "        elif v == -1 and i == len(mark_unstable)-1:\n",
    "            tmp.append(i)\n",
    "            range_unstable.append(tmp)\n",
    "            tmp = []\n",
    "            unstable = False\n",
    "    #print(range_unstable)\n",
    "\n",
    "    filtered_answer = answer\n",
    "\n",
    "    # 생성된 range_unstable를 기반으로 filtering하는 부분\n",
    "    # 각각의 불연속적인 구간에 대해서 양 옆의 gait phase를 확인하고, 그에 맞춰서 불연속적인 구간에 대한 정답보정 \n",
    "    for range_ in range_unstable:\n",
    "\n",
    "        left_class = None\n",
    "        if range_[0]-1 < 0:\n",
    "            left_class = 1 - filtered_answer[range_[1]+1]\n",
    "            #left_class = filtered_answer[range_[1]+1]\n",
    "        else:\n",
    "            left_class = filtered_answer[range_[0]-1]\n",
    "\n",
    "        right_class = None\n",
    "        if range_[1]+1 == len(answer):\n",
    "            right_class = 1 - filtered_answer[range_[0]-1]\n",
    "            #right_class = filtered_answer[range_[0]-1]\n",
    "        else:\n",
    "            right_class = filtered_answer[range_[1] + 1]\n",
    "\n",
    "        for i in range(range_[0], int(sum(range_) / 2)):\n",
    "            filtered_answer[i] = left_class\n",
    "\n",
    "        for i in range(int(sum(range_) / 2), range_[1] + 1):\n",
    "            filtered_answer[i] = right_class\n",
    "    #print(filtered_answer)\n",
    "    return filtered_answer\n",
    "\n",
    "def ModelTest(numFrame, pathCSV, model, PostProcessing_):\n",
    "    data_l, data_r, time, initialContactTime, safe_start, safe_end, pevis2Lankle, pevis2Rankle = ReadCSV(pathCSV)\n",
    "    \n",
    "    l_answer = []\n",
    "    r_answer = []\n",
    "\n",
    "    idx_startframe = safe_start\n",
    "    while (idx_startframe + numFrame-1) <= safe_end:\n",
    "        ## L\n",
    "        input_ = data_l[idx_startframe:idx_startframe+numFrame, :]\n",
    "        min_ = np.min(input_,axis=0)\n",
    "        max_ = np.max(input_,axis=0)\n",
    "        input_ = (input_ - min_) / (max_ - min_)\n",
    "        input_ = np.expand_dims(input_, axis=0)\n",
    "        input_ = torch.FloatTensor(input_).to(device)\n",
    "        h0 = torch.zeros(1, 1, hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, 1, hidden_size).to(device)\n",
    "        pred = model(input_, h0.detach(), c0.detach())\n",
    "        answer = 0\n",
    "        if torch.squeeze(pred) > 0.5:\n",
    "            answer = 1\n",
    "        else:\n",
    "            answer = 0\n",
    "        l_answer.append(answer)\n",
    "\n",
    "        ## R\n",
    "        input_ = data_r[idx_startframe:idx_startframe+numFrame, :]\n",
    "        min_ = np.min(input_,axis=0)\n",
    "        max_ = np.max(input_,axis=0)\n",
    "        input_ = (input_ - min_) / (max_ - min_)\n",
    "        input_ = np.expand_dims(input_, axis=0)\n",
    "        input_ = torch.FloatTensor(input_).to(device)\n",
    "        h0 = torch.zeros(1, 1, hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, 1, hidden_size).to(device)\n",
    "        pred = model(input_, h0.detach(), c0.detach())\n",
    "        answer = 0\n",
    "        if torch.squeeze(pred) > 0.5:\n",
    "            answer = 1\n",
    "        else:\n",
    "            answer = 0\n",
    "        r_answer.append(answer)\n",
    "        idx_startframe += 1\n",
    "\n",
    "    finalAnswer_l = None\n",
    "    finalAnswer_r = None\n",
    "    \n",
    "    if PostProcessing_:\n",
    "        finalAnswer_l = PostProcessing(answer = l_answer, threshold = 3)\n",
    "        finalAnswer_r = PostProcessing(answer = r_answer, threshold = 3)\n",
    "    else:\n",
    "        finalAnswer_l = l_answer\n",
    "        finalAnswer_r = r_answer\n",
    "        \n",
    "    return finalAnswer_l, finalAnswer_r, l_answer, r_answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4963fabc-b707-4e43-bcf5-4c86217fb816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    elif len(l_off_predict) > 1:\\n        for i in range(len(l_off_predict)-1, 0, -1):\\n            #LstrideLength += np.linalg.norm(LAnkle_filtered[l_off_predict[i]+safe_start] - LAnkle_filtered[l_off_predict[i-1]+safe_start])\\n            LstrideLength += abs(LAnkle_filtered[l_off_predict[i]+safe_start, -1] - LAnkle_filtered[l_off_predict[i-1]+safe_start, -1])\\n            count += 1\\n        LstrideLength /= count\\n        LstrideLength /= 10\\n    \\n    elif len(r_off_predict) > 1:\\n        for i in range(len(r_off_predict)-1, 0, -1):\\n            #RstrideLength += np.linalg.norm(RAnkle_filtered[r_off_predict[i]+safe_start] - RAnkle_filtered[r_off_predict[i-1]+safe_start])\\n            RstrideLength += abs(RAnkle_filtered[r_off_predict[i]+safe_start, -1] - RAnkle_filtered[r_off_predict[i-1]+safe_start, -1])\\n            count += 1\\n        RstrideLength /= count\\n        RstrideLength /= 10\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PredictParamters(path, l_contact_predict, l_off_predict, r_contact_predict, r_off_predict, safe_start):\n",
    "    \n",
    "    ## 누락된 데이터 전까지 읽기 위해 line_num 찾는 과정\n",
    "    csv_data = np.loadtxt(path, delimiter=',', dtype=str, skiprows=1, usecols=(1))\n",
    "    line_num=csv_data.shape[0]\n",
    "    for i, v in enumerate(csv_data):\n",
    "        if v == \" \":\n",
    "            line_num = i\n",
    "            break\n",
    "            \n",
    "    csv_data = np.loadtxt(path, delimiter=',', skiprows=1, max_rows=line_num, usecols=range(1, 101))  \n",
    "    \n",
    "    ## 마지막 4개의 항목을 통해 각 데이터가 기록된 시간을 획득(키넥트 기준)\n",
    "    time = csv_data[:,-4:]\n",
    "    time_ = time[:, 0] * 3600 + time[:,1] * 60 + time[:, 2]+ time[:, 3] / 1000.0\n",
    "    time_ = time_ - time_[0]\n",
    "    \n",
    "    ## 발목 데이터 읽어오기\n",
    "    LAnkle_idx = 20\n",
    "    RAnkle_idx = 24\n",
    "    \n",
    "    LAnkle = csv_data[:, LAnkle_idx * 3: (LAnkle_idx + 1) * 3]\n",
    "    RAnkle = csv_data[:, RAnkle_idx * 3: (RAnkle_idx + 1) * 3]\n",
    "        \n",
    "    # LPF를 위한 변수\n",
    "    cutoff = 6\n",
    "    order = 30\n",
    "    LAnkle_filtered = butter_lowpass_filter(LAnkle, cutoff, order)\n",
    "    RAnkle_filtered = butter_lowpass_filter(RAnkle, cutoff, order)\n",
    "    \n",
    "    # strideLength\n",
    "    count = 0\n",
    "    LstrideLength = 0\n",
    "    if len(l_contact_predict) > 1:\n",
    "        for i in range(len(l_contact_predict)-1, 0, -1):\n",
    "            #LstrideLength += np.linalg.norm(LAnkle_filtered[l_contact_predict[i]+safe_start] - LAnkle_filtered[l_contact_predict[i-1]+safe_start])\n",
    "            LstrideLength += abs(LAnkle_filtered[l_contact_predict[i]+safe_start, -1] - LAnkle_filtered[l_contact_predict[i-1]+safe_start, -1])\n",
    "            count += 1\n",
    "        LstrideLength /= count\n",
    "        LstrideLength /= 10 # mm ->cm\n",
    "    else:\n",
    "        LstrideLength = None\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    RstrideLength = 0\n",
    "    if len(r_contact_predict) > 1:\n",
    "        for i in range(len(r_contact_predict)-1, 0, -1):\n",
    "            #RstrideLength += np.linalg.norm(RAnkle_filtered[r_contact_predict[i]+safe_start] - RAnkle_filtered[r_contact_predict[i-1]+safe_start])\n",
    "            RstrideLength += abs(RAnkle_filtered[r_contact_predict[i]+safe_start, -1] - RAnkle_filtered[r_contact_predict[i-1]+safe_start, -1])\n",
    "            count += 1\n",
    "        RstrideLength /= count\n",
    "        RstrideLength /= 10\n",
    "    else:\n",
    "        RstrideLength = None\n",
    "        \n",
    "    # stepLength\n",
    "    stepLength_L = 0\n",
    "    stepLength_R = 0\n",
    "    if len(l_contact_predict) > 0 and len(r_contact_predict) > 0:\n",
    "        count = 0\n",
    "        for i in range(len(l_contact_predict)):\n",
    "            for j in range(len(r_contact_predict)):\n",
    "                if r_contact_predict[j] > l_contact_predict[i]:\n",
    "                    #stepLength_R += np.linalg.norm(RAnkle_filtered[r_contact_predict[j]+safe_start] - LAnkle_filtered[l_contact_predict[i]+safe_start])\n",
    "                    stepLength_R += abs(RAnkle_filtered[r_contact_predict[j]+safe_start, -1] - LAnkle_filtered[l_contact_predict[i]+safe_start, -1])\n",
    "                    count += 1\n",
    "                    break\n",
    "        if count != 0:\n",
    "            stepLength_R /= count\n",
    "            stepLength_R /= 10\n",
    "        else:\n",
    "            stepLength_R = None\n",
    "                    \n",
    "        count = 0\n",
    "        for i in range(len(r_contact_predict)):\n",
    "            for j in range(len(l_contact_predict)):\n",
    "                if l_contact_predict[j] > r_contact_predict[i]:\n",
    "                    #stepLength_L += np.linalg.norm(LAnkle_filtered[l_contact_predict[j]+safe_start] - RAnkle_filtered[r_contact_predict[i]+safe_start])\n",
    "                    stepLength_L += abs(LAnkle_filtered[l_contact_predict[j]+safe_start, -1] - RAnkle_filtered[r_contact_predict[i]+safe_start, -1])\n",
    "                    count += 1\n",
    "                    break\n",
    "        if count != 0:\n",
    "            stepLength_L /= count\n",
    "            stepLength_L /= 10\n",
    "        else:\n",
    "            stepLength_L = None\n",
    "    else:\n",
    "        stepLength_L = None\n",
    "        stepLength_R = None\n",
    "    \n",
    "        \n",
    "    \n",
    "    return LstrideLength, RstrideLength, stepLength_L, stepLength_R\n",
    "\n",
    "\"\"\"\n",
    "    elif len(l_off_predict) > 1:\n",
    "        for i in range(len(l_off_predict)-1, 0, -1):\n",
    "            #LstrideLength += np.linalg.norm(LAnkle_filtered[l_off_predict[i]+safe_start] - LAnkle_filtered[l_off_predict[i-1]+safe_start])\n",
    "            LstrideLength += abs(LAnkle_filtered[l_off_predict[i]+safe_start, -1] - LAnkle_filtered[l_off_predict[i-1]+safe_start, -1])\n",
    "            count += 1\n",
    "        LstrideLength /= count\n",
    "        LstrideLength /= 10\n",
    "    \n",
    "    elif len(r_off_predict) > 1:\n",
    "        for i in range(len(r_off_predict)-1, 0, -1):\n",
    "            #RstrideLength += np.linalg.norm(RAnkle_filtered[r_off_predict[i]+safe_start] - RAnkle_filtered[r_off_predict[i-1]+safe_start])\n",
    "            RstrideLength += abs(RAnkle_filtered[r_off_predict[i]+safe_start, -1] - RAnkle_filtered[r_off_predict[i-1]+safe_start, -1])\n",
    "            count += 1\n",
    "        RstrideLength /= count\n",
    "        RstrideLength /= 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "24e9a393-4d36-43a2-807d-80a12ee34835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LJO_00\n",
      "LJO_01\n",
      "LJO_02\n",
      "LJO_03\n",
      "LJO_04\n",
      "LJO_05\n",
      "LJO_06\n",
      "LJO_07\n",
      "LJO_08\n",
      "LJO_09\n",
      "LJO_10\n",
      "LJO_11\n",
      "LJO_12\n",
      "LJO_13\n",
      "LJO_14\n",
      "LJO_15\n",
      "LJO_16\n",
      "LJO_17\n",
      "LJO_18\n",
      "LJO_19\n",
      "LJO_20\n",
      "LJO_21\n",
      "LJO_22\n",
      "LJO_23\n",
      "LJO_24\n",
      "contact negative\n",
      "['LJH_00', 'LJH_01', 'LJH_02', 'LJH_04', 'LJH_05', 'LJH_06', 'LJH_08', 'LJH_08', 'LJH_09', 'LJH_10', 'LJH_11', 'LJH_12', 'LJH_13', 'LJH_13', 'LJH_14', 'LJH_16', 'LJH_17', 'LJH_18', 'LJH_21', 'KGJ_00', 'KGJ_01', 'KGJ_02', 'KGJ_03', 'KGJ_04', 'KGJ_06', 'KGJ_09', 'KGJ_09', 'KGJ_10', 'KGJ_15', 'KGJ_16', 'KGJ_17', 'KGJ_20', 'KGJ_21', 'KGJ_21', 'KGJ_22', 'KGJ_23', 'KGJ_23', 'KGJ_24', 'KGJ_24', 'KGJ_25', 'KGJ_25', 'NGR_00', 'NGR_01', 'NGR_02', 'NGR_03', 'NGR_05', 'NGR_06', 'NGR_07', 'NGR_08', 'NGR_09', 'NGR_10', 'NGR_12', 'NGR_12', 'NGR_13', 'NGR_14', 'NGR_15', 'NGR_16', 'NGR_16', 'NGR_17', 'NGR_17', 'NGR_18', 'NGR_18', 'NGR_19', 'NGR_19', 'NGR_20', 'NGR_20', 'NGR_21', 'NGR_21', 'NGR_22', 'NGR_22', 'NGR_23', 'NGR_23', 'NGR_24', 'NGR_24', 'CIY_00', 'CIY_01', 'CIY_02', 'CIY_02', 'CIY_03', 'CIY_04', 'CIY_04', 'CIY_05', 'CIY_05', 'CIY_06', 'CIY_06', 'CIY_07', 'CIY_08', 'CIY_09', 'CIY_10', 'CIY_11', 'CIY_12', 'CIY_17', 'CIY_18', 'CIY_20', 'CIY_21', 'CIY_23', 'PKS_01', 'PKS_03', 'PKS_05', 'PKS_06', 'PKS_07', 'PKS_08', 'PKS_09', 'PKS_10', 'PKS_11', 'PKS_15', 'PKS_16', 'PKS_17', 'PKS_19', 'PKS_19', 'PKS_21', 'PKS_22', 'PKS_23', 'KYW_00', 'KYW_01', 'KYW_02', 'KYW_03', 'KYW_12', 'KYW_14', 'KYW_15', 'KYW_16', 'KYW_18', 'KYW_23', 'PBD_00', 'PBD_00', 'PBD_01', 'PBD_02', 'PBD_02', 'PBD_04', 'PBD_04', 'PBD_05', 'PBD_05', 'PBD_06', 'PBD_07', 'PBD_07', 'PBD_08', 'PBD_08', 'PBD_09', 'PBD_09', 'PBD_10', 'PBD_10', 'PBD_11', 'PBD_11', 'PBD_12', 'PBD_12', 'PBD_13', 'PBD_14', 'PBD_15', 'PBD_16', 'PBD_18', 'PBD_18', 'PBD_19', 'PBD_19', 'PBD_20', 'PBD_20', 'PBD_21', 'PBD_21', 'PBD_22', 'PBD_23', 'PBD_23', 'PBD_24', 'PBD_24', 'PBD_25', 'PBD_25', 'PBD_27', 'PBD_27', 'PBD_28', 'PBD_28', 'YGP_00', 'YGP_00', 'YGP_01', 'YGP_03', 'YGP_04', 'YGP_05', 'YGP_06', 'YGP_06', 'YGP_07', 'YGP_09', 'YGP_10', 'YGP_11', 'YGP_12', 'YGP_12', 'YGP_13', 'YGP_16', 'YGP_17', 'YGP_17', 'YGP_18', 'YGP_19', 'YGP_19', 'YGP_20', 'YGP_21', 'YGP_21', 'YGP_22', 'YGP_22', 'YGP_23', 'YGP_23', 'YGD_05', 'YGD_08', 'YGD_10', 'YGD_10', 'YGD_11', 'YGD_17', 'YGD_19', 'YGD_21', 'YGD_23', 'YGD_23', 'YGD_24', 'YGD_24', 'YGD_25', 'YGD_25', 'KYK_00', 'KYK_00', 'KYK_01', 'KYK_01', 'KYK_02', 'KYK_03', 'KYK_04', 'KYK_04', 'KYK_05', 'KYK_06', 'KYK_07', 'KYK_07', 'KYK_08', 'KYK_09', 'KYK_10', 'KYK_11', 'KYK_12', 'KYK_13', 'KYK_14', 'KYK_15', 'KYK_16', 'KYK_16', 'KYK_19', 'KYK_19', 'KYK_20', 'KYK_20', 'KYK_21', 'KYK_21', 'KYK_22', 'KYK_23', 'KYK_23', 'KYK_24', 'KYK_25', 'KYK_25', 'BGS_01', 'BGS_04', 'BGS_05', 'BGS_06', 'BGS_09', 'BGS_11', 'BGS_14', 'BGS_14', 'BGS_15', 'BGS_16', 'BGS_17', 'BGS_19', 'BGS_20', 'BGS_21', 'BGS_22', 'LBN_01', 'LBN_02', 'LBN_02', 'LBN_03', 'LBN_03', 'LBN_04', 'LBN_04', 'LBN_05', 'LBN_05', 'LBN_06', 'LBN_06', 'LBN_07', 'LBN_07', 'LBN_08', 'LBN_08', 'LBN_09', 'LBN_09', 'LBN_10', 'LBN_10', 'LBN_11', 'LBN_11', 'LBN_12', 'LBN_13', 'LBN_13', 'LBN_14', 'LBN_14', 'LBN_15', 'LBN_16', 'LBN_16', 'LBN_17', 'LBN_17', 'LBN_18', 'LBN_18', 'LBN_19', 'LBN_20', 'LBN_21', 'LBN_22', 'LBN_23', 'LBN_23', 'LBN_25', 'LBN_25', 'JSM_00', 'JSM_00', 'JSM_01', 'JSM_02', 'JSM_06', 'JSM_08', 'JSM_09', 'JSM_11', 'JSM_12', 'JSM_14', 'JSM_15', 'JSM_15', 'JSM_16', 'JSM_16', 'JSM_17', 'JSM_17', 'JSM_18', 'JSM_18', 'JSM_19', 'JSM_19', 'JSM_20', 'JSM_22', 'JSM_23', 'JSM_25', 'JSM_25', 'LSH_01', 'LSH_02', 'LSH_03', 'LSH_04', 'LSH_05', 'LSH_06', 'LSH_07', 'LSH_08', 'LSH_09', 'LSH_10', 'LSH_11', 'LSH_13', 'LSH_14', 'LSH_15', 'LSH_16', 'LSH_17', 'LSH_18', 'LSH_19', 'LSH_20', 'LSH_21', 'LSH_22', 'LSH_23', 'LSH_24', 'LSH_24', 'LSH_25', 'LSH_25', 'LSH_26', 'LSH_26', 'LHS_00', 'LHS_01', 'LHS_02', 'LHS_02', 'LHS_03', 'LHS_04', 'LHS_05', 'LHS_06', 'LHS_07', 'LHS_08', 'LHS_09', 'LHS_10', 'LHS_10', 'LHS_12', 'LHS_13', 'LHS_13', 'LHS_17', 'LHS_18', 'LHS_18', 'LHS_19', 'LHS_19', 'LHS_20', 'LHS_20', 'LHS_21', 'LHS_22', 'LHS_23', 'LHS_24', 'LHS_25', 'LHS_25', 'SKY_03', 'SKY_03', 'SKY_09', 'SKY_22', 'SKY_23', 'SKY_24', 'SKY_24', 'CJJ_00', 'CJJ_01', 'CJJ_01', 'CJJ_02', 'CJJ_04', 'CJJ_05', 'CJJ_06', 'CJJ_08', 'CJJ_09', 'CJJ_11', 'CJJ_12', 'CJJ_13', 'CJJ_15', 'CJJ_19', 'CJJ_19', 'CJJ_20', 'CJJ_20', 'CJJ_21', 'CJJ_21', 'CJJ_22', 'CJJ_22', 'CJJ_24', 'CJJ_24', 'CJJ_25', 'CJJ_25', 'CJJ_26', 'CJJ_26', 'RGH_00', 'RGH_03', 'RGH_05', 'RGH_06', 'RGH_06', 'RGH_08', 'RGH_08', 'RGH_09', 'RGH_13', 'RGH_16', 'RGH_18', 'RGH_19', 'RGH_20', 'RGH_21', 'RGH_21', 'RGH_23', 'RGH_23', 'RGH_24', 'JBB_00', 'JBB_01', 'JBB_02', 'JBB_03', 'JBB_04', 'JBB_06', 'JBB_07', 'JBB_08', 'JBB_09', 'JBB_09', 'JBB_10', 'JBB_11', 'JBB_13', 'JBB_14', 'JBB_15', 'JBB_25', 'JBB_26', 'JBB_26', 'PSCD_01', 'PSCD_01', 'PSCD_02', 'PSCD_02', 'PSCD_03', 'PSCD_03', 'PSCD_04', 'PSCD_06', 'PSCD_06', 'PSCD_07', 'PSCD_08', 'PSCD_08', 'PSCD_09', 'PSCD_09', 'PSCD_10', 'PSCD_10', 'PSCD_11', 'PSCD_12', 'PSCD_13', 'PSCD_14', 'PSCD_15', 'PSCD_16', 'PSCD_16', 'PSCD_17', 'PSCD_18', 'PSCD_18', 'PSCD_19', 'PSCD_20', 'PSCD_21', 'PSCD_22', 'PSCD_22', 'PSCD_23', 'PSCD_24', 'PSCD_25', 'KCS_00', 'KCS_01', 'KCS_02', 'KCS_03', 'KCS_03', 'KCS_04', 'KCS_05', 'KCS_05', 'KCS_06', 'KCS_07', 'KCS_09', 'KCS_11', 'KCS_11', 'KCS_12', 'KCS_14', 'KCS_15', 'KCS_17', 'KCS_17', 'KCS_18', 'KCS_19', 'KCS_20', 'KCS_21', 'KCS_22', 'KCS_23', 'KCS_24', 'KCS_25', 'KSJ_01', 'KSJ_01', 'KSJ_02', 'KSJ_02', 'KSJ_03', 'KSJ_03', 'KSJ_04', 'KSJ_05', 'KSJ_05', 'KSJ_06', 'KSJ_06', 'KSJ_07', 'KSJ_08', 'KSJ_09', 'KSJ_10', 'KSJ_11', 'KSJ_12', 'KSJ_13', 'KSJ_14', 'KSJ_16', 'KSJ_17', 'KSJ_18', 'KSJ_19', 'KSJ_20', 'KSJ_21', 'KSJ_22', 'KSJ_22', 'KSJ_23', 'KSJ_24', 'KSJ_24', 'KSJ_25', 'KSJ_25', 'HJJ_01', 'HJJ_01', 'HJJ_02', 'HJJ_02', 'HJJ_03', 'HJJ_03', 'HJJ_04', 'HJJ_04', 'HJJ_06', 'HJJ_06', 'HJJ_07', 'HJJ_07', 'HJJ_08', 'HJJ_08', 'HJJ_09', 'HJJ_09', 'HJJ_10', 'HJJ_10', 'HJJ_11', 'HJJ_11', 'HJJ_12', 'HJJ_12', 'HJJ_13', 'HJJ_13', 'HJJ_14', 'HJJ_14', 'HJJ_15', 'HJJ_15', 'HJJ_16', 'HJJ_17', 'HJJ_18', 'HJJ_18', 'HJJ_19', 'HJJ_20', 'HJJ_20', 'HJJ_21', 'HJJ_21', 'HJJ_22', 'HJJ_22', 'HJJ_23', 'HJJ_23', 'HJJ_24', 'HJJ_24', 'HJJ_25', 'HJJ_25', 'HJJ_26', 'HJJ_26', 'HJJ_27', 'HJJ_27', 'HJJ_28', 'HJJ_28', 'HJJ_29', 'HJJ_29', 'LJO_00', 'LJO_01', 'LJO_02', 'LJO_04', 'LJO_04', 'LJO_05', 'LJO_06', 'LJO_07', 'LJO_08', 'LJO_09', 'LJO_10', 'LJO_11', 'LJO_12', 'LJO_13', 'LJO_14', 'LJO_15', 'LJO_15', 'LJO_17', 'LJO_17', 'LJO_18', 'LJO_18', 'LJO_19', 'LJO_19', 'LJO_20', 'LJO_20', 'LJO_21', 'LJO_21', 'LJO_22', 'LJO_22', 'LJO_23', 'LJO_23', 'LJO_24', 'LJO_24']\n",
      "off negative\n",
      "['LJH_01', 'LJH_02', 'LJH_08', 'LJH_11', 'LJH_13', 'LJH_13', 'LJH_18', 'KGJ_06', 'KGJ_08', 'KGJ_09', 'KGJ_10', 'KGJ_11', 'KGJ_13', 'KGJ_15', 'KGJ_16', 'KGJ_20', 'KGJ_20', 'KGJ_21', 'KGJ_22', 'KGJ_22', 'KGJ_23', 'KGJ_23', 'KGJ_24', 'KGJ_25', 'KGJ_25', 'NGR_01', 'NGR_02', 'NGR_02', 'NGR_06', 'NGR_07', 'NGR_12', 'NGR_13', 'NGR_15', 'NGR_16', 'NGR_17', 'NGR_17', 'NGR_18', 'NGR_19', 'NGR_19', 'NGR_20', 'NGR_21', 'NGR_22', 'NGR_22', 'NGR_23', 'NGR_23', 'NGR_24', 'CIY_01', 'CIY_02', 'CIY_03', 'CIY_03', 'CIY_04', 'CIY_05', 'CIY_05', 'CIY_06', 'CIY_06', 'CIY_07', 'CIY_08', 'CIY_09', 'CIY_10', 'CIY_11', 'CIY_12', 'CIY_14', 'CIY_21', 'CIY_22', 'CIY_23', 'CIY_23', 'PKS_00', 'PKS_04', 'PKS_05', 'PKS_09', 'PKS_10', 'PKS_21', 'PKS_22', 'KYW_01', 'KYW_02', 'KYW_11', 'KYW_12', 'KYW_14', 'KYW_18', 'KYW_19', 'KYW_20', 'KYW_21', 'KYW_22', 'KYW_23', 'KYW_23', 'PBD_00', 'PBD_01', 'PBD_02', 'PBD_04', 'PBD_04', 'PBD_05', 'PBD_06', 'PBD_08', 'PBD_10', 'PBD_10', 'PBD_11', 'PBD_15', 'PBD_16', 'PBD_16', 'PBD_18', 'PBD_19', 'PBD_19', 'PBD_20', 'PBD_21', 'PBD_21', 'PBD_22', 'PBD_23', 'PBD_23', 'PBD_24', 'PBD_24', 'PBD_25', 'PBD_25', 'PBD_27', 'PBD_27', 'PBD_28', 'YGP_03', 'YGP_06', 'YGP_07', 'YGP_10', 'YGP_12', 'YGP_12', 'YGP_16', 'YGP_17', 'YGP_18', 'YGP_18', 'YGP_19', 'YGP_21', 'YGP_22', 'YGP_22', 'YGP_23', 'YGP_23', 'YGD_05', 'YGD_06', 'YGD_08', 'YGD_10', 'YGD_10', 'YGD_23', 'YGD_24', 'YGD_24', 'YGD_25', 'KYK_00', 'KYK_01', 'KYK_02', 'KYK_02', 'KYK_04', 'KYK_04', 'KYK_05', 'KYK_06', 'KYK_08', 'KYK_09', 'KYK_10', 'KYK_10', 'KYK_11', 'KYK_12', 'KYK_13', 'KYK_13', 'KYK_14', 'KYK_14', 'KYK_16', 'KYK_16', 'KYK_19', 'KYK_20', 'KYK_20', 'KYK_21', 'KYK_21', 'KYK_22', 'KYK_22', 'KYK_23', 'KYK_24', 'KYK_24', 'KYK_25', 'KYK_25', 'BGS_04', 'BGS_05', 'BGS_14', 'LBN_01', 'LBN_02', 'LBN_03', 'LBN_05', 'LBN_06', 'LBN_08', 'LBN_09', 'LBN_10', 'LBN_11', 'LBN_13', 'LBN_16', 'LBN_17', 'LBN_18', 'LBN_19', 'LBN_20', 'LBN_21', 'LBN_22', 'LBN_23', 'LBN_25', 'JSM_00', 'JSM_00', 'JSM_03', 'JSM_03', 'JSM_09', 'JSM_16', 'JSM_16', 'JSM_25', 'LSH_01', 'LSH_03', 'LSH_05', 'LSH_06', 'LSH_07', 'LSH_07', 'LSH_08', 'LSH_09', 'LSH_10', 'LSH_11', 'LSH_13', 'LSH_15', 'LSH_18', 'LSH_19', 'LSH_19', 'LSH_20', 'LSH_22', 'LSH_24', 'LSH_25', 'LSH_26', 'LSH_26', 'LHS_03', 'LHS_05', 'LHS_10', 'LHS_12', 'LHS_13', 'LHS_13', 'LHS_14', 'LHS_16', 'LHS_18', 'LHS_18', 'LHS_19', 'LHS_19', 'LHS_20', 'LHS_20', 'LHS_21', 'LHS_22', 'SKY_03', 'SKY_15', 'SKY_16', 'SKY_22', 'SKY_23', 'SKY_24', 'CJJ_00', 'CJJ_01', 'CJJ_01', 'CJJ_04', 'CJJ_06', 'CJJ_08', 'CJJ_10', 'CJJ_12', 'CJJ_13', 'CJJ_14', 'CJJ_18', 'CJJ_19', 'CJJ_20', 'CJJ_20', 'CJJ_21', 'CJJ_21', 'CJJ_22', 'CJJ_22', 'CJJ_24', 'CJJ_24', 'CJJ_25', 'CJJ_25', 'CJJ_26', 'CJJ_26', 'RGH_00', 'RGH_00', 'RGH_03', 'RGH_08', 'RGH_16', 'RGH_19', 'RGH_20', 'RGH_21', 'RGH_23', 'RGH_23', 'JBB_01', 'JBB_04', 'JBB_07', 'JBB_08', 'JBB_09', 'JBB_12', 'JBB_13', 'JBB_26', 'PSCD_01', 'PSCD_01', 'PSCD_02', 'PSCD_02', 'PSCD_03', 'PSCD_06', 'PSCD_07', 'PSCD_08', 'PSCD_09', 'PSCD_10', 'PSCD_12', 'PSCD_12', 'PSCD_15', 'PSCD_16', 'PSCD_16', 'PSCD_18', 'PSCD_19', 'PSCD_20', 'PSCD_21', 'PSCD_22', 'PSCD_22', 'PSCD_25', 'KCS_01', 'KCS_01', 'KCS_05', 'KCS_06', 'KCS_14', 'KCS_15', 'KCS_17', 'KCS_17', 'KCS_19', 'KCS_19', 'KCS_20', 'KCS_20', 'KCS_21', 'KCS_24', 'KCS_25', 'KSJ_01', 'KSJ_01', 'KSJ_02', 'KSJ_03', 'KSJ_05', 'KSJ_07', 'KSJ_08', 'KSJ_09', 'KSJ_10', 'KSJ_13', 'KSJ_14', 'KSJ_15', 'KSJ_18', 'KSJ_19', 'KSJ_22', 'HJJ_01', 'HJJ_01', 'HJJ_02', 'HJJ_02', 'HJJ_03', 'HJJ_03', 'HJJ_04', 'HJJ_06', 'HJJ_06', 'HJJ_07', 'HJJ_07', 'HJJ_08', 'HJJ_08', 'HJJ_09', 'HJJ_10', 'HJJ_11', 'HJJ_11', 'HJJ_12', 'HJJ_13', 'HJJ_13', 'HJJ_14', 'HJJ_15', 'HJJ_16', 'HJJ_18', 'HJJ_18', 'HJJ_19', 'HJJ_19', 'HJJ_20', 'HJJ_20', 'HJJ_21', 'HJJ_21', 'HJJ_22', 'HJJ_22', 'HJJ_23', 'HJJ_23', 'HJJ_24', 'HJJ_24', 'HJJ_25', 'HJJ_25', 'HJJ_26', 'HJJ_26', 'HJJ_27', 'HJJ_27', 'HJJ_28', 'HJJ_28', 'HJJ_29', 'HJJ_29', 'LJO_02', 'LJO_04', 'LJO_08', 'LJO_10', 'LJO_10', 'LJO_11', 'LJO_12', 'LJO_15', 'LJO_15', 'LJO_16', 'LJO_18', 'LJO_23', 'LJO_24']\n",
      "classificationAcc_final :  80.0758879121397  coverageAcc_contact_final :  46.610169491525426  coverageAcc_off_final :  66.1864406779661  FrameError_contact_final :  6.886233507592731  FrameError_off_final :  5.411347517730497\n"
     ]
    }
   ],
   "source": [
    "def getResults(root, numFrame, drawing):\n",
    "    totalFrame = 0\n",
    "    classification_positive = 0\n",
    "    numTrial = 0\n",
    "    numContact = 0\n",
    "    numOff = 0\n",
    "    \n",
    "    count_contact = 0\n",
    "    count_off = 0\n",
    "    \n",
    "    FrameError_contact = 0\n",
    "    FrameError_off = 0\n",
    "    coverage_positive_contact = 0\n",
    "    coverage_positive_off = 0\n",
    "    coverage_negative_contact_list = []\n",
    "    coverage_negative_off_list = []\n",
    "    \n",
    "    Error_strideLength_L = []\n",
    "    Error_strideLength_R = []\n",
    "    Error_stepLength_L = []\n",
    "    Error_stepLength_R = []\n",
    "    \n",
    "    count_strideLength_L = 0\n",
    "    count_strideLength_R = 0\n",
    "    count_stepLength_L = 0\n",
    "    count_stepLength_R = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    names = []\n",
    "    for name in next(os.walk(root))[1]:\n",
    "        names.append(name)\n",
    "    #print(names)\n",
    "    errorFiles = []\n",
    "\n",
    "    #drawing을 위한 폴더 생성\n",
    "    if drawing:\n",
    "        if not os.path.isdir(\"./testResult\"):\n",
    "            os.mkdir(\"testResult\")\n",
    "        else:\n",
    "            shutil.rmtree(\"testResult\")\n",
    "            os.mkdir(\"testResult\")\n",
    "    \n",
    "            \n",
    "    for name in names:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        pathPerson = os.path.join(root, name)\n",
    "        (root_, Folders, csvFiles) = next(os.walk(pathPerson))\n",
    "        Folders = sorted(Folders)\n",
    "        csvFiles = sorted(csvFiles)\n",
    "\n",
    "        if '.ipynb_checkpoints' in Folders:\n",
    "            Folders.remove('.ipynb_checkpoints')\n",
    "        if '.ipynb_checkpoints' in csvFiles:\n",
    "            csvFiles.remove('.ipynb_checkpoints')\n",
    "        if len(Folders) != len(csvFiles):\n",
    "            print(name, ' is not matched')\n",
    "            break\n",
    "\n",
    "        for idx_file in range(len(csvFiles)):\n",
    "            pathCSV = os.path.join(pathPerson, csvFiles[idx_file])\n",
    "            pathForceData = os.path.join(pathPerson, Folders[idx_file])\n",
    "            \n",
    "            \n",
    "            print(csvFiles[idx_file].split('.')[0])\n",
    "            \n",
    "            # 데이터 읽기\n",
    "            data_l, data_r, time, initialContactTime, safe_start, safe_end, pevis2Lankle, pevis2Rankle = ReadCSV(pathCSV)\n",
    "            l_contact, l_off, r_contact, r_off, parameters = ReadForceData(pathForceData)\n",
    "            \n",
    "            \n",
    "            # 싱크 맞추기\n",
    "            firstContact = min(r_contact[0], l_contact[0]) # zebris 기준 최초 contact 찾음\n",
    "            timeGap = initialContactTime - firstContact # sync.kinect 기준으로 모든 시간 변환\n",
    "            l_contact = l_contact + timeGap\n",
    "            l_off = l_off + timeGap\n",
    "            r_contact = r_contact + timeGap\n",
    "            r_off = r_off + timeGap\n",
    "\n",
    "            # 정답 라벨\n",
    "            l_contact_ = []\n",
    "            for i in l_contact:\n",
    "                tmp = abs(time - i)\n",
    "                l_contact_.append(np.argmin(tmp))\n",
    "            l_off_ = []\n",
    "            for i in l_off:\n",
    "                tmp = abs(time - i)\n",
    "                l_off_.append(np.argmin(tmp))\n",
    "\n",
    "            l_label = np.zeros(data_l.shape[0])\n",
    "            for i in range(len(l_contact_)):\n",
    "                for j in range(l_contact_[i], l_off_[i]):\n",
    "                    l_label[j] = 1\n",
    "\n",
    "            r_contact_ = []\n",
    "            for i in r_contact:\n",
    "                tmp = abs(time - i)\n",
    "                r_contact_.append(np.argmin(tmp))\n",
    "            r_off_ = []\n",
    "            for i in r_off:\n",
    "                tmp = abs(time - i)\n",
    "                r_off_.append(np.argmin(tmp))\n",
    "\n",
    "            r_label = np.zeros(data_r.shape[0])\n",
    "            for i in range(len(r_contact_)):\n",
    "                for j in range(r_contact_[i], r_off_[i]):\n",
    "                    r_label[j] = 1\n",
    "            \n",
    "            ## 인공지능 결과\n",
    "            finalAnswer_l, finalAnswer_r, modelOutput_l, modelOutput_r = ModelTest(numFrame = numFrame, pathCSV = pathCSV, model = model, PostProcessing_ = True)\n",
    "            \n",
    "            ## Rulebased 방식 결과\n",
    "            #finalAnswer_l, finalAnswer_r, modelOutput_l, modelOutput_r = ruleBased(numFrame = numFrame, safe_start=safe_start, safe_end=safe_end, pevis2Lankle=pevis2Lankle, pevis2Rankle=pevis2Rankle, PostProcessing_=False) \n",
    "\n",
    "            # Left gait events \n",
    "            l_contact_predict = []\n",
    "            l_off_predict = []\n",
    "            \n",
    "            prev = finalAnswer_l[0]\n",
    "            for i, v in enumerate(finalAnswer_l):\n",
    "                if prev != v:\n",
    "                    if prev == 0:\n",
    "                        l_contact_predict.append(i)\n",
    "                    elif prev == 1:\n",
    "                        l_off_predict.append(i)\n",
    "                prev = v\n",
    "                \n",
    "            # Right gait events \n",
    "            r_contact_predict = []\n",
    "            r_off_predict = []\n",
    "            \n",
    "            prev = finalAnswer_r[0]\n",
    "            for i, v in enumerate(finalAnswer_r):\n",
    "                if prev != v:\n",
    "                    if prev == 0:\n",
    "                        r_contact_predict.append(i)\n",
    "                    elif prev == 1:\n",
    "                        r_off_predict.append(i)\n",
    "                prev = v\n",
    "\n",
    "            # Drawing\n",
    "            if drawing:\n",
    "                x_new = np.linspace(time[0], time[-1], len(time))\n",
    "                \n",
    "                if drawing == 1:\n",
    "                    ## Type 1 : Deep learning Input + Label + Prediction\n",
    "                    # Left Input\n",
    "                    fig, axs = plt.subplots(3, figsize=(18,12))\n",
    "                    axs[0].set_title('Left')\n",
    "                    axs[0].plot(x_new, data_l[:,0], 'r-', label = 'Hip')\n",
    "                    axs[0].plot(x_new, data_l[:,1], 'b-', label = 'Knee')\n",
    "                    axs[0].plot(x_new, data_l[:,4], 'k-', label = 'AnkleDistance')\n",
    "                    for i in l_contact_:\n",
    "                        axs[0].axvline(x = time[i], c='r')\n",
    "                    for i in l_off_:\n",
    "                        axs[0].axvline(x = time[i], c='b')\n",
    "                    axs[0].legend()\n",
    "\n",
    "                    axs[1].set_title('True Label')\n",
    "                    axs[1].axvline(x = time[safe_start], label='safe Start = {}'.format(safe_start), c='g')\n",
    "                    axs[1].axvline(x = time[safe_end], label='safe End = {}'.format(safe_end), c='g')\n",
    "                    for i in l_contact_:\n",
    "                        axs[1].axvline(x = time[i], label='LContact = {}'.format(i), c='r')\n",
    "                    for i in l_off_:\n",
    "                        axs[1].axvline(x = time[i], label='LOff = {}'.format(i), c='b')\n",
    "\n",
    "                    for i, v in enumerate(l_label):\n",
    "                        if v == 1:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 1, 'b.', label='Swing')\n",
    "                                axs[1].plot(time[i], 1, 'r.', label='Stance')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 1, 'r.')\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 0, 'r.', label='Stance')\n",
    "                                axs[1].plot(time[i], 0, 'b.', label='Swing')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 0, 'b.')\n",
    "                    axs[1].legend()\n",
    "\n",
    "                    ## Left PostProcessing\n",
    "                    axs[2].set_title('Prediction')\n",
    "                    axs[2].axvline(x = time[safe_start], c='g')\n",
    "                    axs[2].axvline(x = time[safe_end], c='g')\n",
    "                    for i, v in enumerate(finalAnswer_l):\n",
    "                        if v == 1:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 1, 'r.')\n",
    "                        else:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 0, 'b.')\n",
    "                    for i in l_contact_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='LContact = {}'.format(i), c='r')\n",
    "                    for i in l_off_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='LOff = {}'.format(i), c='b')\n",
    "                    axs[2].legend()\n",
    "\n",
    "                    for ax in axs:\n",
    "                        ax.set_xlim([time[0], time[-1]])  \n",
    "\n",
    "                    fig.tight_layout()\n",
    "                    plt.savefig('testResult//' + csvFiles[idx_file].split('.')[0] + '_Left_Type1.jpg')\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "                    # Right Input\n",
    "                    fig, axs = plt.subplots(3, figsize=(18,12))\n",
    "                    axs[0].set_title('Right')\n",
    "                    axs[0].plot(x_new, data_r[:,0], 'r-', label = 'Hip')\n",
    "                    axs[0].plot(x_new, data_r[:,1], 'b-', label = 'Knee')\n",
    "                    axs[0].plot(x_new, data_r[:,4], 'k-', label = 'AnkleDistance')\n",
    "                    for i in r_contact_:\n",
    "                        axs[0].axvline(x = time[i], c='r')\n",
    "                    for i in r_off_:\n",
    "                        axs[0].axvline(x = time[i], c='b')\n",
    "                    axs[0].legend()\n",
    "\n",
    "                    axs[1].set_title('True Label')\n",
    "                    axs[1].axvline(x = time[safe_start], label='safe Start = {}'.format(safe_start), c='g')\n",
    "                    axs[1].axvline(x = time[safe_end], label='safe End = {}'.format(safe_end), c='g')\n",
    "                    for i in r_contact_:\n",
    "                        axs[1].axvline(x = time[i], label='RContact = {}'.format(i), c='r')\n",
    "                    for i in r_off_:\n",
    "                        axs[1].axvline(x = time[i], label='ROff = {}'.format(i), c='b')\n",
    "\n",
    "                    for i, v in enumerate(r_label):\n",
    "                        if v == 1:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 1, 'b.', label='Swing')\n",
    "                                axs[1].plot(time[i], 1, 'r.', label='Stance')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 1, 'r.')\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 0, 'r.', label='Stance')\n",
    "                                axs[1].plot(time[i], 0, 'b.', label='Swing')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 0, 'b.')\n",
    "                    axs[1].legend()\n",
    "\n",
    "                    ## Right PostProcessing\n",
    "                    axs[2].set_title('Prediction')\n",
    "                    axs[2].axvline(x = time[safe_start], c='g')\n",
    "                    axs[2].axvline(x = time[safe_end], c='g')\n",
    "                    for i, v in enumerate(finalAnswer_r):\n",
    "                        if v == 1:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 1, 'r.')\n",
    "                        else:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 0, 'b.')\n",
    "                    for i in r_contact_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='RContact = {}'.format(i), c='r')\n",
    "                    for i in r_off_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='ROff = {}'.format(i), c='b')\n",
    "                    axs[2].legend()\n",
    "\n",
    "                    for ax in axs:\n",
    "                        ax.set_xlim([time[0], time[-1]])  \n",
    "\n",
    "                    fig.tight_layout()\n",
    "                    plt.savefig('testResult//' + csvFiles[idx_file].split('.')[0] + '_Right_Type1.jpg')\n",
    "                    plt.close()\n",
    "                    \n",
    "                elif drawing == 2:\n",
    "                    ## Type 2 : Rule Based Input + Label + Prediction\n",
    "                    # Left Input\n",
    "                    fig, axs = plt.subplots(3, figsize=(18,12))\n",
    "                    axs[0].set_title('Left')\n",
    "                    axs[0].plot(x_new, pevis2Lankle[:,-1], 'k-', label = 'pevis2Lankle')\n",
    "                    for i in l_contact_:\n",
    "                        axs[0].axvline(x = time[i], c='r')\n",
    "                    for i in l_off_:\n",
    "                        axs[0].axvline(x = time[i], c='b')\n",
    "                    axs[0].set_ylim([np.min(pevis2Lankle[:,-1]), np.max(pevis2Lankle[:,-1])]) \n",
    "                    \n",
    "                    axs[0].axvline(x = time[np.argmax(pevis2Lankle[:,-1])], c = 'k', ls='--')\n",
    "                    axs[0].axvline(x = time[np.argmin(pevis2Lankle[:,-1])], c = 'k', ls='--')\n",
    "                    \n",
    "                    axs[0].legend()\n",
    "\n",
    "                    axs[1].set_title('True Label')\n",
    "                    axs[1].axvline(x = time[safe_start], label='safe Start = {}'.format(safe_start), c='g')\n",
    "                    axs[1].axvline(x = time[safe_end], label='safe End = {}'.format(safe_end), c='g')\n",
    "                    for i in l_contact_:\n",
    "                        axs[1].axvline(x = time[i], label='LContact = {}'.format(i), c='r')\n",
    "                    for i in l_off_:\n",
    "                        axs[1].axvline(x = time[i], label='LOff = {}'.format(i), c='b')\n",
    "\n",
    "                    for i, v in enumerate(l_label):\n",
    "                        if v == 1:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 1, 'b.', label='Swing')\n",
    "                                axs[1].plot(time[i], 1, 'r.', label='Stance')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 1, 'r.')\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 0, 'r.', label='Stance')\n",
    "                                axs[1].plot(time[i], 0, 'b.', label='Swing')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 0, 'b.')\n",
    "                    axs[1].legend()\n",
    "\n",
    "                    ## Left PostProcessing\n",
    "                    axs[2].set_title('Prediction')\n",
    "                    axs[2].axvline(x = time[safe_start], c='g')\n",
    "                    axs[2].axvline(x = time[safe_end], c='g')\n",
    "                    for i, v in enumerate(finalAnswer_l):\n",
    "                        if v == 1:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 1, 'r.')\n",
    "                        else:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 0, 'b.')\n",
    "                    for i in l_contact_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='LContact = {}'.format(i), c='r')\n",
    "                    for i in l_off_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='LOff = {}'.format(i), c='b')\n",
    "                    axs[2].legend()\n",
    "\n",
    "                    for ax in axs:\n",
    "                        ax.set_xlim([time[0], time[-1]])  \n",
    "\n",
    "                    fig.tight_layout()\n",
    "                    plt.savefig('testResult//' + csvFiles[idx_file].split('.')[0] + '_Left_Type2.jpg')\n",
    "                    plt.close()\n",
    "\n",
    "                    # Right Input\n",
    "                    fig, axs = plt.subplots(3, figsize=(18,12))\n",
    "                    axs[0].set_title('Right')\n",
    "                    axs[0].plot(pevis2Rankle[:,-1], 'k-', label = 'pevis2Rankle')\n",
    "                    for i in r_contact_:\n",
    "                        axs[0].axvline(x = time[i], c='r')\n",
    "                    for i in r_off_:\n",
    "                        axs[0].axvline(x = time[i], c='b')\n",
    "                    axs[0].legend()\n",
    "\n",
    "                    axs[1].set_title('True Label')\n",
    "                    axs[1].axvline(x = time[safe_start], label='safe Start = {}'.format(safe_start), c='g')\n",
    "                    axs[1].axvline(x = time[safe_end], label='safe End = {}'.format(safe_end), c='g')\n",
    "                    for i in r_contact_:\n",
    "                        axs[1].axvline(x = time[i], label='LContact = {}'.format(i), c='r')\n",
    "                    for i in r_off_:\n",
    "                        axs[1].axvline(x = time[i], label='LOff = {}'.format(i), c='b')\n",
    "\n",
    "                    for i, v in enumerate(r_label):\n",
    "                        if v == 1:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 1, 'b.', label='Swing')\n",
    "                                axs[1].plot(time[i], 1, 'r.', label='Stance')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 1, 'r.')\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                axs[1].plot(time[i], 0, 'r.', label='Stance')\n",
    "                                axs[1].plot(time[i], 0, 'b.', label='Swing')\n",
    "                            else:\n",
    "                                axs[1].plot(time[i], 0, 'b.')\n",
    "                    axs[1].legend()\n",
    "\n",
    "                    ## Right PostProcessing\n",
    "                    axs[2].set_title('Prediction')\n",
    "                    axs[2].axvline(x = time[safe_start], c='g')\n",
    "                    axs[2].axvline(x = time[safe_end], c='g')\n",
    "                    for i, v in enumerate(finalAnswer_r):\n",
    "                        if v == 1:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 1, 'r.')\n",
    "                        else:\n",
    "                            axs[2].plot(time[i + safe_start + numFrame - 1], 0, 'b.')\n",
    "                    for i in r_contact_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='RContact = {}'.format(i), c='r')\n",
    "                    for i in r_off_predict:\n",
    "                        axs[2].axvline(x = time[i + safe_start + numFrame - 1], label='ROff = {}'.format(i), c='b')\n",
    "                    axs[2].legend()\n",
    "\n",
    "                    fig.tight_layout()\n",
    "\n",
    "                    for ax in axs:\n",
    "                        ax.set_xlim([time[0], time[-1]])  \n",
    "\n",
    "\n",
    "                    plt.savefig('testResult//' + csvFiles[idx_file].split('.')[0] + '_Right_Type2.jpg')\n",
    "                    plt.close()\n",
    "                    \n",
    "            # Gait Event True\n",
    "            # Left\n",
    "            l_label = l_label[safe_start + numFrame - 1:safe_end + 1]\n",
    "            l_contact_true = []\n",
    "            l_off_true = []\n",
    "            \n",
    "            prev = l_label[0]\n",
    "            for i, v in enumerate(l_label):\n",
    "                if prev != v:\n",
    "                    if prev == 0:\n",
    "                        l_contact_true.append(i-1)\n",
    "                    elif prev == 1:\n",
    "                        l_off_true.append(i-1)\n",
    "                prev = v\n",
    "            # Right\n",
    "            r_label = r_label[safe_start + numFrame - 1:safe_end + 1]\n",
    "            r_contact_true = []\n",
    "            r_off_true = []\n",
    "            \n",
    "            prev = r_label[0]\n",
    "            for i, v in enumerate(r_label):\n",
    "                if prev != v:\n",
    "                    if prev == 0:\n",
    "                        r_contact_true.append(i-1)\n",
    "                    elif prev == 1:\n",
    "                        r_off_true.append(i-1)\n",
    "                prev = v\n",
    "                \n",
    "            # Coverage\n",
    "            # Left Contact\n",
    "            if len(l_contact_predict) == len(l_contact_true):\n",
    "                coverage_positive_contact += 1\n",
    "            else:\n",
    "                coverage_negative_contact_list.append(csvFiles[idx_file].split('.')[0])\n",
    "\n",
    "            # Left Toe Off\n",
    "            if len(l_off_predict) == len(l_off_true):\n",
    "                numOff += len(l_off_predict)\n",
    "                for i in range(len(l_off_predict)):\n",
    "                    FrameError_off+=abs(l_off_predict[i] - l_off_true[i])\n",
    "                coverage_positive_off += 1\n",
    "            else:\n",
    "                coverage_negative_off_list.append(csvFiles[idx_file].split('.')[0])\n",
    "            \n",
    "            # Right Contact\n",
    "            if len(r_contact_predict) == len(r_contact_true):\n",
    "                numContact += len(r_contact_predict)\n",
    "                for i in range(len(r_contact_predict)):\n",
    "                    FrameError_contact += abs(r_contact_predict[i] - r_contact_true[i])\n",
    "                coverage_positive_contact += 1\n",
    "            else:\n",
    "                coverage_negative_contact_list.append(csvFiles[idx_file].split('.')[0])\n",
    "            \n",
    "            # Right Toe Off\n",
    "            if len(r_off_predict) == len(r_off_true):\n",
    "                numOff += len(r_contact_predict)\n",
    "                for i in range(len(r_off_predict)):\n",
    "                    FrameError_off += abs(r_off_predict[i] - r_off_true[i])\n",
    "                coverage_positive_off += 1\n",
    "            else:\n",
    "                coverage_negative_off_list.append(csvFiles[idx_file].split('.')[0])\n",
    "                \n",
    "                \n",
    "            # Frame Error for Contact\n",
    "            numContact += len(l_contact_predict)\n",
    "            \n",
    "            if len(l_contact_predict) > 0 and len(l_contact_true) > 0:\n",
    "                numContact += len(l_contact_predict)\n",
    "                for i in range(len(l_contact_predict)):\n",
    "                    tmpList_abs = [abs(x - l_contact_predict[i]) for x in l_contact_true]    \n",
    "                    FrameError_contact += min(tmpList_abs)\n",
    "                    \n",
    "            if len(r_contact_predict) > 0 and len(r_contact_true) > 0:\n",
    "                numContact += len(r_contact_predict)\n",
    "                for i in range(len(r_contact_predict)):\n",
    "                    tmpList_abs = [abs(x - r_contact_predict[i]) for x in r_contact_true]  \n",
    "                    FrameError_contact += min(tmpList_abs)\n",
    "\n",
    "            # Frame Error for Toe off\n",
    "            if len(l_off_predict) > 0 and len(l_off_true) > 0: \n",
    "                numOff += len(l_off_predict)\n",
    "                for i in range(len(l_off_predict)):\n",
    "                    tmpList_abs = [abs(x - l_off_predict[i]) for x in l_off_true]  \n",
    "                    FrameError_off += min(tmpList_abs)\n",
    "                    \n",
    "            if len(r_off_predict) > 0 and len(r_off_true) > 0: \n",
    "                numOff += len(r_off_predict)\n",
    "                for i in range(len(r_off_predict)):\n",
    "                    tmpList_abs = [abs(x - r_off_predict[i]) for x in r_off_true]  \n",
    "                    FrameError_off += min(tmpList_abs)\n",
    "                \n",
    "            # classification Acc\n",
    "            totalFrame += len(l_label)\n",
    "            for i in range(len(l_label)):\n",
    "                if l_label[i] == finalAnswer_l[i]:\n",
    "                    classification_positive += 1\n",
    "            totalFrame += len(r_label)\n",
    "            for i in range(len(r_label)):\n",
    "                if r_label[i] == finalAnswer_r[i]:\n",
    "                    classification_positive += 1\n",
    "                    \n",
    "            # Gait Parameters, Zebris에서 제공하는 값. 일단은 안씀\n",
    "            stepLength_L = parameters.values.tolist()[0][0]\n",
    "            stancePhase_L = parameters.values.tolist()[0][1]\n",
    "            \n",
    "            stepLength_R = parameters.values.tolist()[0][2]\n",
    "            stancePhase_R = parameters.values.tolist()[0][3]\n",
    "            \n",
    "            strideLength = parameters.values.tolist()[0][4]\n",
    "            Cadence = parameters.values.tolist()[0][5]\n",
    "            Velocity = parameters.values.tolist()[0][6]\n",
    "\n",
    "            LstrideLength_true, RstrideLength_true, LstepLength_true, RstepLength_true = PredictParamters(pathCSV, l_contact_true, l_off_true, r_contact_true, r_off_true, safe_start)\n",
    "            LstrideLength_pred, RstrideLength_pred, LstepLength_pred, RstepLength_pred = PredictParamters(pathCSV, l_contact_predict, l_off_predict, r_contact_predict, r_off_predict, safe_start)\n",
    "                           \n",
    "            if LstrideLength_true is not None and LstrideLength_pred is not None:\n",
    "                Error_strideLength_L.append(LstrideLength_true - LstrideLength_pred)\n",
    "                count_strideLength_L += 1\n",
    "            if RstrideLength_true is not None and RstrideLength_pred is not None:\n",
    "                Error_strideLength_R.append(RstrideLength_true - RstrideLength_pred)\n",
    "                count_strideLength_R += 1\n",
    "                \n",
    "            if LstepLength_true is not None and LstepLength_pred is not None:\n",
    "                Error_stepLength_L.append(LstepLength_true - LstepLength_pred)\n",
    "                count_stepLength_L += 1\n",
    "            if RstepLength_true is not None and RstepLength_pred is not None:\n",
    "                Error_stepLength_R.append(RstepLength_true - RstepLength_pred)\n",
    "                count_stepLength_R += 1\n",
    "                \n",
    "            numTrial += 2\n",
    "            \n",
    "    print('contact negative')\n",
    "    print(coverage_negative_contact_list)\n",
    "    print('off negative')\n",
    "    print(coverage_negative_off_list)\n",
    "    classificationAcc_final = classification_positive * 100 / totalFrame\n",
    "    coverageAcc_contact_final = coverage_positive_contact * 100 / numTrial\n",
    "    coverageAcc_off_final = coverage_positive_off * 100 / numTrial\n",
    "    FrameError_contact_final = None\n",
    "    if numContact != 0:\n",
    "        FrameError_contact_final = FrameError_contact / numContact\n",
    "    FrameError_off_final = None\n",
    "    if numOff != 0:\n",
    "        FrameError_off_final = FrameError_off / numOff\n",
    "        \n",
    "    finalError_stepLength_L_mean = 0\n",
    "    finalError_stepLength_L_std = 0\n",
    "    if count_stepLength_L > 0:\n",
    "        finalError_stepLength_L_mean = np.mean(Error_stepLength_L)\n",
    "        finalError_stepLength_L_std = np.std(Error_stepLength_L)\n",
    "        \n",
    "    finalError_stepLength_R_mean = 0\n",
    "    finalError_stepLength_R_std = 0\n",
    "    if count_stepLength_R > 0:\n",
    "        finalError_stepLength_R_mean = np.mean(Error_stepLength_R)\n",
    "        finalError_stepLength_R_std = np.std(Error_stepLength_R)\n",
    "        \n",
    "    finalError_strideLength_L_mean = 0\n",
    "    finalError_strideLength_L_std = 0\n",
    "    if count_strideLength_L > 0:\n",
    "        finalError_strideLength_L_mean = np.mean(Error_strideLength_L)\n",
    "        finalError_strideLength_L_std = np.std(Error_strideLength_L)\n",
    "        \n",
    "    finalError_strideLength_R_mean = 0\n",
    "    finalError_strideLength_R_std = 0\n",
    "    if count_strideLength_R > 0:\n",
    "        finalError_strideLength_R_mean = np.mean(Error_strideLength_R)\n",
    "        finalError_strideLength_R_std = np.std(Error_strideLength_R)\n",
    "        \n",
    "    f = open(\"testResult//_Result.txt\", 'w')\n",
    "    tmp = f'classificationAcc_final : {classificationAcc_final:.3f} \\ncoverageAcc_contact_final : {coverageAcc_contact_final:.3f} \\\n",
    "    \\ncoverageAcc_off_final : {coverageAcc_off_final:.3f} \\nFrameError_contact_final : {FrameError_contact_final:.3f} \\\n",
    "    \\nFrameError_off_final : {FrameError_off_final:.3f} \\nfinalError_stepLength_L_mean(cm) : {finalError_stepLength_L_mean:.3f} \\\n",
    "    \\nfinalError_stepLength_L_std(cm) : {finalError_stepLength_L_std:.3f} \\nfinalError_stepLength_R_mean(cm) : {finalError_stepLength_R_mean:.3f} \\\n",
    "    \\nfinalError_stepLength_R_std(cm) : {finalError_stepLength_R_std:.3f} \\nfinalError_strideLength_L_mean(cm) : {finalError_strideLength_L_mean:.3f} \\\n",
    "    \\nfinalError_strideLength_L_std(cm) : {finalError_strideLength_L_std:.3f} \\nfinalError_strideLength_R_mean(cm) : {finalError_strideLength_R_mean:.3f} \\\n",
    "    \\nfinalError_strideLength_R_std(cm) : {finalError_strideLength_R_std:.3f}'\n",
    "    f.write(str(tmp))\n",
    "    f.close\n",
    "\n",
    "    return classificationAcc_final, coverageAcc_contact_final, coverageAcc_off_final, FrameError_contact_final, FrameError_off_final\n",
    "\n",
    "classificationAcc_final, coverageAcc_contact_final, coverageAcc_off_final, FrameError_contact_final, FrameError_off_final = getResults(root='Dataset_old', numFrame=10, drawing=1)\n",
    "print('classificationAcc_final : ', classificationAcc_final, ' coverageAcc_contact_final : ', coverageAcc_contact_final, ' coverageAcc_off_final : ', coverageAcc_off_final, ' FrameError_contact_final : ', FrameError_contact_final, ' FrameError_off_final : ', FrameError_off_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c7131-8f8c-489d-8205-db82ef2ef081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
